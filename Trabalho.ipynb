{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0509 10:22:12.345640 21848 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:63: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import dtypes, random_seed\n",
    "\n",
    "#DataSet constructor, used to store an monochromatic image based dataset\n",
    "#dtype can be either uint8 to leave the input as [0, 255], or float32 to rescale into [0, 1].\n",
    "#Seed arg provides for convenient deterministic testing.\n",
    "class DataSet(object):\n",
    "    def __init__(self, images, labels, dtype = dtypes.float32, reshape = True, seed = None):\n",
    "        seed1, seed2 = random_seed.get_seed(seed)\n",
    "\n",
    "        #If op level seed is not set, use whatever graph level seed is returned\n",
    "        numpy.random.seed(seed1 if seed is None else seed2)\n",
    "        dtype = dtypes.as_dtype(dtype).base_dtype\n",
    "\n",
    "        if dtype not in (dtypes.uint8, dtypes.float32):\n",
    "            raise TypeError('Invalid image dtype %r, expected uint8 or float32' % dtype)\n",
    "\n",
    "        assert images.shape[0] == labels.shape[0], ('images.shape: %s labels.shape: %s' % (images.shape, labels.shape))\n",
    "\n",
    "        self.num_examples = images.shape[0]\n",
    "\n",
    "        #Convert shape from [num examples, rows, columns, depth] to [num examples, rows*columns](assuming depth == 1)\n",
    "        if reshape:\n",
    "            assert images.shape[3] == 1\n",
    "            images = images.reshape(images.shape[0], images.shape[1] * images.shape[2])\n",
    "\n",
    "        #Convert from [0, 255] -> [0.0, 1.0].\n",
    "        if dtype == dtypes.float32:\n",
    "            images = images.astype(numpy.float32)\n",
    "            images = numpy.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.epochs_completed = 0\n",
    "        self.index_in_epoch = 0\n",
    "\n",
    "    #Return the next batch_size examples from this data set\n",
    "    def next_batch(self, batch_size, shuffle=True):\n",
    "        start = self.index_in_epoch\n",
    "\n",
    "        #Shuffle for the first epoch\n",
    "        if self.epochs_completed == 0 and start == 0 and shuffle:\n",
    "            perm0 = numpy.arange(self.num_examples)\n",
    "            numpy.random.shuffle(perm0)\n",
    "            self.images = self.images[perm0]\n",
    "            self.labels = self.labels[perm0]\n",
    "\n",
    "        #Get Next epoch\n",
    "        if start + batch_size > self.num_examples:\n",
    "            #Finished epoch\n",
    "            self.epochs_completed += 1\n",
    "\n",
    "            #Get the rest examples in this epoch\n",
    "            rest_num_examples = self.num_examples - start\n",
    "            images_rest_part = self.images[start:self.num_examples]\n",
    "            labels_rest_part = self.labels[start:self.num_examples]\n",
    "\n",
    "            #Shuffle the data\n",
    "            if shuffle:\n",
    "                perm = numpy.arange(self.num_examples)\n",
    "                numpy.random.shuffle(perm)\n",
    "                self.images = self.images[perm]\n",
    "                self.labels = self.labels[perm]\n",
    "\n",
    "            #Start next epoch\n",
    "            start = 0\n",
    "            self.index_in_epoch = batch_size - rest_num_examples\n",
    "            end = self.index_in_epoch\n",
    "            images_new_part = self.images[start:end]\n",
    "            labels_new_part = self.labels[start:end]\n",
    "            return numpy.concatenate((images_rest_part, images_new_part), axis=0) , numpy.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "        else:\n",
    "            self.index_in_epoch += batch_size\n",
    "            end = self.index_in_epoch\n",
    "            return self.images[start:end], self.labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy\n",
    "from random import shuffle\n",
    "from tensorflow.python.framework import dtypes\n",
    "\n",
    "Datasets = collections.namedtuple('Datasets', ['train', 'validation', 'test'])\n",
    "\n",
    "def read_data_semeion(fname = 'data/semeion.data'):\n",
    "    file = open(fname, 'r')\n",
    "    lines = file.readlines()\n",
    "\n",
    "    width = 16\n",
    "    height = 16\n",
    "    size = width * height\n",
    "    classes = 10\n",
    "\n",
    "    images = [];\n",
    "    labels = [];\n",
    "    fnumber = 0;\n",
    "\n",
    "    for line in lines:\n",
    "        data = line.split(' ')\n",
    "        image = [];\n",
    "        label = [];\n",
    "\n",
    "        for i in range(0, size):\n",
    "            image.append(int(float(data[i])))\n",
    "        images.append(image)\n",
    "\n",
    "        for i in range(size, size + classes):\n",
    "            label.append(int(float(data[i]))) \n",
    "        labels.append(label)\n",
    "\n",
    "        fnumber += 1\n",
    "        \n",
    "    #Shuffle data\n",
    "    images_shuffle = []\n",
    "    labels_shuffle = []\n",
    "    indexes = list(range(len(images)))\n",
    "    shuffle(indexes)\n",
    "    for i in indexes:\n",
    "        images_shuffle.append(images[i])\n",
    "        labels_shuffle.append(labels[i])\n",
    "\n",
    "    images = images_shuffle\n",
    "    labels = labels_shuffle\n",
    "\n",
    "    samples = len(lines)\n",
    "    train_samples = int(0.8*samples)\n",
    "    test_samples = int(0.2*samples)\n",
    "\n",
    "    #Train set\n",
    "    image_train = numpy.array(images[:train_samples], dtype=numpy.uint8)\n",
    "    image_train = image_train.reshape(train_samples, width, height, 1)\n",
    "\n",
    "    label_train = numpy.array(labels[:train_samples], dtype=numpy.uint8)\n",
    "\n",
    "    train = DataSet(image_train, label_train, reshape=True)\n",
    "\n",
    "    #test set\n",
    "    image_test = numpy.array(images[test_samples:], dtype=numpy.uint8)\n",
    "    image_test = image_test.reshape(samples - test_samples, width, height, 1)\n",
    "\n",
    "    label_test = numpy.array(labels[test_samples:], dtype=numpy.uint8)\n",
    "\n",
    "    test = DataSet(image_test, label_test, reshape=True)\n",
    "\n",
    "    return Datasets(train=train, validation=data, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_0 = tf.placeholder(tf.float32, [None, 256])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "middle = 30\n",
    "w_1 = tf.Variable(tf.truncated_normal([256, middle]))\n",
    "b_1 = tf.Variable(tf.truncated_normal([1, middle]))\n",
    "w_2 = tf.Variable(tf.truncated_normal([middle, 10]))\n",
    "b_2 = tf.Variable(tf.truncated_normal([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return tf.div(tf.constant(1.0),\n",
    "                  tf.add(tf.constant(1.0), tf.exp(tf.negative(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0509 13:45:34.254946 21848 deprecation.py:323] From <ipython-input-6-2b83e92b7715>:3: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "z_1 = tf.add(tf.matmul(a_0, w_1), b_1)\n",
    "a_1 = sigma(z_1)\n",
    "z_2 = tf.add(tf.matmul(a_1, w_2), b_2)\n",
    "a_2 = sigma(z_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = tf.subtract(a_2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmaprime(x):\n",
    "    return tf.multiply(sigma(x), tf.subtract(tf.constant(1.0), sigma(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z_2 = tf.multiply(diff, sigmaprime(z_2))\n",
    "d_b_2 = d_z_2\n",
    "d_w_2 = tf.matmul(tf.transpose(a_1), d_z_2)\n",
    "\n",
    "d_a_1 = tf.matmul(d_z_2, tf.transpose(w_2))\n",
    "d_z_1 = tf.multiply(d_a_1, sigmaprime(z_1))\n",
    "d_b_1 = d_z_1\n",
    "d_w_1 = tf.matmul(tf.transpose(a_0), d_z_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = tf.constant(0.5)\n",
    "step = [\n",
    "    tf.assign(w_1,\n",
    "            tf.subtract(w_1, tf.multiply(eta, d_w_1)))\n",
    "  , tf.assign(b_1,\n",
    "            tf.subtract(b_1, tf.multiply(eta,\n",
    "                               tf.reduce_mean(d_b_1, axis=[0]))))\n",
    "  , tf.assign(w_2,\n",
    "            tf.subtract(w_2, tf.multiply(eta, d_w_2)))\n",
    "  , tf.assign(b_2,\n",
    "            tf.subtract(b_2, tf.multiply(eta,\n",
    "                               tf.reduce_mean(d_b_2, axis=[0]))))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ed01b6268ce9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                        {a_0: dataset.test.images, y: dataset.test.labels})\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         tf.train.write_graph(my_graph, path_to_model_pb,\n\u001b[0m\u001b[0;32m     18\u001b[0m                      'saved_model.pb', as_text=False)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_graph' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = read_data_semeion()\n",
    "\n",
    "acct_mat = tf.equal(tf.argmax(a_2, 1), tf.argmax(y, 1))\n",
    "acct_res = tf.reduce_sum(tf.cast(acct_mat, tf.float32))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_x, batch_y = dataset.train.next_batch(10)\n",
    "    sess.run(step, feed_dict = {a_0: batch_x,\n",
    "                                y : batch_y})\n",
    "    if i % 1000 == 0:\n",
    "        res = sess.run(acct_res, feed_dict =\n",
    "                       {a_0: dataset.test.images, y: dataset.test.labels})\n",
    "        print(res)\n",
    "        tf.train.write_graph(my_graph, path_to_model_pb,\n",
    "                     'saved_model.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
